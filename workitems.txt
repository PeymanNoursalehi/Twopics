[1] Data Collection
    - Twitter API, mining 1000 tweets for
        - #olympics
        - #2012olympics
        - #londonolympics
    - remove duplicate tweets, aggregate all tweets

[2] Synonym Expansion
    - Use Oxford Thesaurus to get synonyms for all words (w) possible
    - Use UNTIndexer to get top n (4) synonyms for each w
    - Constraint: only use 3grams
        - Using SaLSA - part of SaLSA can be reused
        - Changes in SaLSA
            - new synonyms.db (from Oxford)
            - how the final results returned are handled
    - Add the synonyms to the overall tweet
    - (future work) - take multiwords. For now, multiwords from Oxford are discarded, because they likely won't get any count from Web1T if a tweet word is replaced with multiwords

[3] Cleaning
    - remove 
        - stop words 
        - hyperlinks
        - Twitter stop words and punctuation (@, #, RT, MT)
        - punctuation
        - alphanumeric words

[4] Keyword Extraction
    - alternative to previously thought part of speech tagging to derive keywords:
    - use SF-URI database to retain only interesting keywords 
        (those that are there in the database)
        - filter the existing SF-URI database to output only single-word, 4-character-or-more surface forms
        - use this new data to get keywords for all tweets
    - future work
        - do pairwise active context (Web count based similarity)
        - context for every keyword = all remaining keywords for that tweet
            - normalize to a value between 0 and 1
        - take top 4 (as more than 4 do not help in disambiguation)
        - for every tweet, produce (id, [(keyword, [context]) ...]) tuple
    - outcome
        - tweet_id :: keyword1 keyword2 ... \n ...

[5] Disambiguation
    - for every tweet
        - for every keyword
            - pick all senses from Wikipedia for all contexts
            - remove stop words, pick top N words from all contexts
            - build vectors for each sense
            - the columns are TF-IDF (ICF) scores
            - build a vector for the keyword
                - aggregate of the keyword and context words
            - do a cosine similarity and pick a sense
        - build an aggregated vector for the tweet

[6] Build Wikipedia class data structure    
    - Start from the Wikipedia class hierarchy
    - build static vectors for all nodes (categories)
    - build a way to navigate the hierarchy
        - tree? something pre-existing?

[7] Fine tune the disambiguation
    - navigate the tree using cosine similarities between vectors
    - see how deep we can go

